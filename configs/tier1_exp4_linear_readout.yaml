# Tier 1 - Experiment 4: PCA linear readout baseline
# Tests if dimensionality reduction alone captures predictable structure.

seed: 42
slice: all

data:
  latents_dir: ./outputs/phase0/latents.zarr
  latents_index: ./outputs/phase0/latents_index.parquet
  frames_index: ./outputs/phase0/phase0_frames.parquet
  splits_dir: ./outputs/phase0/splits
  min_duration_sec: 3.0

pca_dims: [32, 64]

context:
  window_size: 8
  horizons_k: [1, 2, 4, 8]

# Reduced hidden_dim since input dims are much smaller (8*32=256 for PCA32)
model:
  n_components: 8
  hidden_dim: 512
  n_hidden_layers: 2
  dropout: 0.0
  min_log_sigma: -7.0
  max_log_sigma: 2.0

train:
  device: auto
  seed: 42
  batch_size: 256
  num_workers: 0
  compile: false
  compile_mode: default
  amp: false
  amp_dtype: bf16
  max_steps: 15000
  lr: 1.0e-3
  weight_decay: 1.0e-4
  grad_clip_norm: 1.0
  log_every: 200
  eval_every: 2000
  save_every: 5000
  max_train_samples: null
  max_eval_samples: 200000
  shuffle_buffer: 8192

rollout:
  enabled: true
  n_eval_utterances: 16
  max_frames_per_utterance: 2000
  sample_from_mixture: false

injection:
  k_steps: 16
  n_eval_utterances: 16
  segments_per_utt: 8
  max_frames_per_utterance: 2000
  inject_after_steps_periodic: [4, 8, 12]
  inject_after_steps_one_shot: [1]
  max_train_samples: null

output:
  out_dir: ./outputs/tier1/exp4_linear_readout
